{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def addElement(array, index, ele):\n",
    "    if array and index < len(array):\n",
    "        array[index] += ele\n",
    "        return array\n",
    "    newArray = [0] * (index + 1)\n",
    "    if array:\n",
    "        newArray[:len(array)] = array\n",
    "    newArray[index] = ele\n",
    "    return newArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trafficRecordsById = {}\n",
    "startTime = 1433142000\n",
    "\n",
    "with open(\"new.csv\") as f:\n",
    "    trafficRecords = csv.reader(f, delimiter=',')\n",
    "    count = 0\n",
    "    for trafficRecord in trafficRecords:\n",
    "        if count % 100000 == 0:\n",
    "            print (count / 24015249 * 100, \"%\")\n",
    "#         if count == 30000:\n",
    "#             break\n",
    "        recordTime = trafficRecord[1]\n",
    "        checkPointId = trafficRecord[2]\n",
    "        lane = int(trafficRecord[3])\n",
    "        traffic = int(trafficRecord[4])\n",
    "\n",
    "        relativeTime = time.mktime(datetime.datetime.strptime(recordTime, \"%Y-%m-%d %H:%M:%S\").timetuple()) - startTime\n",
    "#         print (relativeTime)\n",
    "        intervalId = relativeTime // 300\n",
    "#         print (intervalId)\n",
    "        \n",
    "        trafficRecordsForId = trafficRecordsById.get(checkPointId)\n",
    "        if not trafficRecordsForId:\n",
    "            trafficByLane = addElement(None, lane, traffic)\n",
    "            trafficRecordsById[checkPointId] = [(intervalId, trafficByLane)]\n",
    "        else:\n",
    "            prevIntervalId = trafficRecordsForId[-1][0]\n",
    "            prevTrafficByLane = trafficRecordsForId[-1][1]\n",
    "            if (intervalId == prevIntervalId):\n",
    "                trafficRecordsForId[-1] = (intervalId, addElement(prevTrafficByLane, lane, traffic))\n",
    "            else:\n",
    "                trafficRecordsForId.append((intervalId, addElement(None, lane, traffic)))\n",
    "        count += 1\n",
    "                \n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle.dump(trafficRecordsById, open(\"trafficRecordsById.p\", \"wb\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "trafficRecordsByIdLoaded = pickle.load(open(\"trafficRecordsById.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def checkMissingSpots(checkPointId):\n",
    "    trafficRecordsForId = trafficRecordsByIdLoaded.get(checkPointId)\n",
    "    prevIndex = -1\n",
    "    for trafficRecord in trafficRecordsForId:\n",
    "        intervalId = trafficRecord[0]\n",
    "        if intervalId != prevIndex + 1:\n",
    "            print (prevIndex, intervalId)\n",
    "        prevIndex = intervalId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import bisect\n",
    "def plotTrafficDistribution(checkPointId, timeRange=(None, None), plot=True):\n",
    "    trafficRecordsForId = trafficRecordsByIdLoaded.get(checkPointId)\n",
    "    if trafficRecordsForId is None:\n",
    "        return\n",
    "    keys = [ele[0] for ele in trafficRecordsForId]\n",
    "    \n",
    "    startIntervalId = timeRange[0]\n",
    "    endIntervalId = timeRange[1]\n",
    "\n",
    "    startIndex = 0\n",
    "    endIndex = len(trafficRecordsForId)\n",
    "    \n",
    "    if startIntervalId is not None:\n",
    "        startIndex = bisect.bisect_left(keys, startIntervalId)\n",
    "    \n",
    "    if endIntervalId is not None:\n",
    "        endIndex = bisect.bisect_right(keys, endIntervalId)\n",
    "        \n",
    "    if plot:\n",
    "        x, y = zip(*((ele[0], sum(ele[1])) for ele in trafficRecordsForId[startIndex: endIndex]))\n",
    "\n",
    "        plt.plot(x, y)\n",
    "        plt.show()\n",
    "        \n",
    "    return trafficRecordsForId[startIndex: endIndex]\n",
    "    \n",
    "plotTrafficDistribution(\"704\", (0, 576))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "checkMissingSpots(\"704\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.1911240257\n",
      "211.074833496\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    yTrueFiltered = []\n",
    "    yPredFiltered = []\n",
    "    \n",
    "    for index, trueValue in enumerate(y_true):\n",
    "        if trueValue < 5:\n",
    "            continue\n",
    "        yTrueFiltered.append(trueValue)\n",
    "        yPredFiltered.append(y_pred[index])\n",
    "        \n",
    "    yTrueFiltered = np.array(yTrueFiltered)\n",
    "    yPredFiltered = np.array(yPredFiltered)\n",
    "    return np.mean(np.abs((yTrueFiltered - yPredFiltered) / yTrueFiltered) * 100)\n",
    "\n",
    "def intervalToRecords(trafficRecordsForId):\n",
    "    intervalToRecordsMap = {}\n",
    "    for trafficRecord in trafficRecordsForId:\n",
    "        intervalToRecordsMap[trafficRecord[0]] = trafficRecord[1]\n",
    "    return intervalToRecordsMap\n",
    "\n",
    "def createDatasetSinglePoint(checkPointId):\n",
    "    trafficRecordsForId = trafficRecordsByIdLoaded.get(checkPointId)\n",
    "    intervalToRecordsMap = intervalToRecords(trafficRecordsForId)\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for trafficRecord in trafficRecordsForId:\n",
    "        intervalId = trafficRecord[0]\n",
    "        timeInterval = intervalId % (288 * 7)\n",
    "        traffic1 = sum(intervalToRecordsMap.get(intervalId - 1)) if intervalToRecordsMap.get(intervalId - 1) is not None else None\n",
    "        traffic2 = sum(intervalToRecordsMap.get(intervalId - 2)) if intervalToRecordsMap.get(intervalId - 2) is not None else None\n",
    "        traffic3 = sum(intervalToRecordsMap.get(intervalId - 3)) if intervalToRecordsMap.get(intervalId - 3) is not None else None\n",
    "        traffic4 = sum(intervalToRecordsMap.get(intervalId - 4)) if intervalToRecordsMap.get(intervalId - 4) is not None else None\n",
    "        traffic288 = sum(intervalToRecordsMap.get(intervalId - 288)) if intervalToRecordsMap.get(intervalId - 288) is not None else None\n",
    "        \n",
    "        trafficDelta1 = (traffic1 - traffic2) if None not in (traffic1, traffic2) else None \n",
    "        trafficDelta2 = (traffic2 - traffic3) if None not in (traffic2, traffic3) else None\n",
    "        \n",
    "#         print (traffic1, traffic2, traffic3)\n",
    "        if None in (traffic1, traffic2, traffic3, traffic4, traffic288, trafficDelta1, trafficDelta2):\n",
    "            continue\n",
    "        y.append(sum(trafficRecord[1]))\n",
    "        X.append([\n",
    "            timeInterval,\n",
    "            traffic1,\n",
    "            traffic2,\n",
    "            traffic3,\n",
    "            traffic4,\n",
    "            traffic288,\n",
    "            trafficDelta1,\n",
    "            trafficDelta2])\n",
    "    return X, y\n",
    "\n",
    "def createDatasetWithSurroundingPoints(checkPointId):\n",
    "    trafficRecordsForId = trafficRecordsByIdLoaded.get(checkPointId)\n",
    "    intervalToRecordsMap = intervalToRecords(trafficRecordsForId)\n",
    "    \n",
    "    intervalToRecordsMapsSurroundings = list(map(intervalToRecords, map(trafficRecordsByIdLoaded.get, [checkPointId, \"707\", \"405\"])))\n",
    "#     print (len(intervalToRecordsMapsSurroundings))\n",
    "    X = []\n",
    "    y = []\n",
    "    for trafficRecord in trafficRecordsForId:\n",
    "        intervalId = trafficRecord[0]\n",
    "        timeInterval = intervalId % 288\n",
    "        toAppend = [timeInterval]\n",
    "        for intervalToRecordsMapsSurrounding in intervalToRecordsMapsSurroundings:\n",
    "            traffic1 = sum(intervalToRecordsMapsSurrounding.get(intervalId - 1)) if intervalToRecordsMapsSurrounding.get(intervalId - 1) is not None else None\n",
    "            traffic2 = sum(intervalToRecordsMapsSurrounding.get(intervalId - 2)) if intervalToRecordsMapsSurrounding.get(intervalId - 2) is not None else None\n",
    "            traffic3 = sum(intervalToRecordsMapsSurrounding.get(intervalId - 3)) if intervalToRecordsMapsSurrounding.get(intervalId - 3) is not None else None\n",
    "            traffic4 = sum(intervalToRecordsMapsSurrounding.get(intervalId - 4)) if intervalToRecordsMapsSurrounding.get(intervalId - 4) is not None else None\n",
    "            traffic288 = sum(intervalToRecordsMapsSurrounding.get(intervalId - 288)) if intervalToRecordsMapsSurrounding.get(intervalId - 288) is not None else None\n",
    "            \n",
    "            trafficDelta1 = (traffic1 - traffic2) if None not in (traffic1, traffic2) else None \n",
    "            trafficDelta2 = (traffic2 - traffic3) if None not in (traffic2, traffic3) else None\n",
    "            \n",
    "            toAppend.extend([traffic1, traffic2, traffic3, traffic4, traffic288, trafficDelta1, trafficDelta2])\n",
    "        if None in toAppend:\n",
    "            continue\n",
    "        y.append(sum(trafficRecord[1]))\n",
    "#         print (toAppend)\n",
    "        X.append(toAppend)\n",
    "    return X, y\n",
    "\n",
    "def gbm(checkPointId):\n",
    "    trafficRecordsForId = trafficRecordsByIdLoaded.get(checkPointId)\n",
    "    X, y = createDatasetSinglePoint(checkPointId)\n",
    "    splitPoint = len(trafficRecordsForId) // 10 * 8\n",
    "    X_train, X_test = X[:splitPoint], X[splitPoint:]\n",
    "    y_train, y_test = y[:splitPoint], y[splitPoint:]\n",
    "    est = GradientBoostingRegressor(n_estimators=300, learning_rate=0.02,\n",
    "        max_depth=5, random_state=0, loss='huber').fit(X_train, y_train)\n",
    "    print (mape(y_test, est.predict(X_test)))\n",
    "    print (mean_squared_error(y_test, est.predict(X_test)))\n",
    "    \n",
    "gbm(\"704\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def lstm(checkPointId):\n",
    "    trafficRecordsForId = trafficRecordsByIdLoaded.get(checkPointId)\n",
    "    numpy.random.seed(7)\n",
    "\n",
    "    X, y = createDataset(checkPointId)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    y = np.reshape(y, (-1, 1))\n",
    "#     print (y)\n",
    "    \n",
    "    dataSet = np.concatenate((X, y), axis=1)\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    dataSet = scaler.fit_transform(dataSet)\n",
    "\n",
    "    X, y = np.hsplit(dataSet, np.array([7]))\n",
    "    \n",
    "    splitPoint = len(trafficRecordsForId) // 10 * 9\n",
    "    X_train, X_test = X[:splitPoint], X[splitPoint:]\n",
    "    y_train, y_test = y[:splitPoint], y[splitPoint:]\n",
    "    \n",
    "    X_train = numpy.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "    X_test = numpy.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "#     print (X_train.shape)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(40, 3)))\n",
    "#     model.add(Dense(1))\n",
    "#     model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "#     model.fit(X_train, y_train, epochs=100, batch_size=1, verbose=2)\n",
    "    \n",
    "    print (mape(y_test, model.predict(X_test)))\n",
    "\n",
    "lstm(\"704\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
